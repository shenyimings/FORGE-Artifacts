{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the audit reports via Cloudflare R2 Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-Only API Token\n",
    "R2_ENDPOINT= \"https://5f0c0f9b5170d2fe9310473a3da483af.r2.cloudflarestorage.com\"\n",
    "R2_ACCESS_KEY_ID = \"77107a604647ebcd016f76fc419d3f2c\"\n",
    "R2_SECRET_ACCESS_KEY=\"14c93e49b06e0d3889e76b771c082ac4e1f7dfd8c429e3e3f548039e3ad36ea2\"\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_r2_client(endpoint_url, access_key_id, secret_access_key):\n",
    "    return boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=endpoint_url,\n",
    "        aws_access_key_id=access_key_id,\n",
    "        aws_secret_access_key=secret_access_key\n",
    "    )\n",
    "\n",
    "def download_file(client, bucket_name, object_key, local_path):\n",
    "    \"\"\"Download a file from the bucket\"\"\"\n",
    "    try:\n",
    "        response = client.head_object(Bucket=bucket_name, Key=object_key)\n",
    "        file_size = response['ContentLength']\n",
    "        \n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "        \n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=f\"Download {object_key}\") as pbar:\n",
    "            client.download_file(\n",
    "                bucket_name, \n",
    "                object_key, \n",
    "                local_path,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Download error ({object_key}): {e}\")\n",
    "        return False\n",
    "\n",
    "def list_objects(client, bucket_name, prefix=\"\"):\n",
    "    \"\"\"List all objects in the bucket\"\"\"\n",
    "    objects = []\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    try:\n",
    "        for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "            if 'Contents' in page:\n",
    "                for obj in page['Contents']:\n",
    "                    objects.append(obj['Key'])\n",
    "    except Exception as e:\n",
    "        print(f\"List object error: {e}\")\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def download_dataset(client, bucket_name, prefix=\"\", output_dir=\"./download\"):\n",
    "    \"\"\"Download all objects in the bucket\"\"\"\n",
    "    print(f\"List objects in bucket {bucket_name} with prefix {prefix}\")\n",
    "    objects = list_objects(client, bucket_name, prefix)\n",
    "    if not objects:\n",
    "        print(f\"No object found in bucket {bucket_name}\")\n",
    "        return 0, 0\n",
    "    \n",
    "    print(f\"Find {len(objects)} objects in bucket {bucket_name}\")\n",
    "    \n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for obj_key in objects:\n",
    "        # Remove the prefix from the object key\n",
    "        if prefix and obj_key.startswith(prefix):\n",
    "            rel_path = obj_key[len(prefix):].lstrip('/')\n",
    "        else:\n",
    "            rel_path = obj_key\n",
    "            \n",
    "        local_path = os.path.join(output_dir, rel_path)\n",
    "        \n",
    "        if download_file(client, bucket_name, obj_key, local_path):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            error_count += 1\n",
    "    \n",
    "    return success_count, error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    endpoint = R2_ENDPOINT\n",
    "    access_key = R2_ACCESS_KEY_ID\n",
    "    secret_key = R2_SECRET_ACCESS_KEY\n",
    "    bucket = \"forge-dataset\"\n",
    "    prefix = \"artifacts\"\n",
    "    output = \"./artifacts\"\n",
    "\n",
    "args = Args()\n",
    "client = get_r2_client(args.endpoint, args.access_key, args.secret_key)\n",
    "print(f\"Start downloading dataset from bucket {args.bucket} with prefix {args.prefix} to {args.output}\")\n",
    "success, error = download_dataset(client, args.bucket, args.prefix, args.output)\n",
    "print(f\"Download completed. Successful: {success} files, Failed: {error} files\")\n",
    "if success > 0:\n",
    "    print(f\"Downloaded files are saved to {args.output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
